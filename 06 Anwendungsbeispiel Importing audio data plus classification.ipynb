{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Import of audio data with classification\n",
    "\n",
    "Das Ziel dieses Beispieles ist es die Arbeit mit Audiodaten, den Import, die Vorbereitung und die Klassifikation zu erklären. Dabei werden folgende Schritte durchgeführt:\n",
    "\n",
    "- Dynamisches Laden und entpacken der Audiodaten von einer externen Quelle\n",
    "- Review der Organisation auf dem Filesystem\n",
    "- Laden der Daten\n",
    "- Transformationen\n",
    "- Training\n",
    "- Analyse\n",
    "\n",
    "Der verwendete Datensatz heisst ESC-50 [1] mit 50 Klassen von Geräuschen in Dateien organisiert. Die Audiodaten sind jeweils 5 Sekunden lang und haben 40 Samples pro Klasse.\n",
    "\n",
    "\n",
    "Der Code für das Beispiel is aus [2] und [3] kombiniert.\n",
    "\n",
    "\n",
    "Quellen für die Beispiele und Daten:\n",
    "\n",
    "- [1] [https://github.com/karolpiczak/ESC-50/blob/master/LICENSE](https://github.com/karolpiczak/ESC-50/blob/master/LICENSE) (Hinweise auf Unterlizenzen der Daten)\n",
    "- [2] [https://github.com/CarmineCella/esc50_keras/blob/master/esc50_keras.py](https://github.com/CarmineCella/esc50_keras/blob/master/esc50_keras.py)\n",
    "- [3] [https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7](https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7)\n",
    "\n",
    "Zitat der Datenquelle:\n",
    "```\n",
    "K. J. Piczak. ESC: Dataset for Environmental Sound Classification. Proceedings of the 23rd Annual ACM Conference on Multimedia, Brisbane, Australia, 2015.\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os.path\n",
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.svm import SVC\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#\n",
    "# Abdrehen von Fehlermeldungen\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Für GPU Support\n",
    "#\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDataSource = 'https://github.com/karoldvl/ESC-50/archive/master.zip'\n",
    "localExtractionFolder = 'data/ESC-50'\n",
    "localDataArchive = 'data/ESC-50/master.zip'\n",
    "\n",
    "sampleLen = 110250 # in samples is 5 sec @ 22050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Daten von einer URL\n",
    "#\n",
    "def download_dataset(url,dataset_file_path):\n",
    "    if os.path.exists(localDataArchive):\n",
    "        print(\"archive already downloaded.\")\n",
    "    else:\n",
    "        print(\"started loading archive from url {}\".format(url))\n",
    "        filename, headers = urlretrieve(url, dataset_file_path)\n",
    "        print(\"finished loading archive from url {}\".format(url))\n",
    "\n",
    "def extract_dataset(dataset_file_path, extraction_directory):    \n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)        \n",
    "    zip = zipfile.ZipFile(dataset_file_path)\n",
    "    zip.extractall(path=extraction_directory)        \n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Laden der Daten ausführen\n",
    "#\n",
    "download_dataset(urlDataSource,localDataArchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction of dataset from data/ESC-50/master.zip to data/ESC-50 done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Extrahieren der Daten\n",
    "#\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation von Audiodaten auf dem Filesystem\n",
    "\n",
    "Die Audiodateien liegen alle in einem Verzeichnis. Die Zuordnung der Klasse ist im Dateinamen kodiert und in einer Datenbank gespeichert.\n",
    "Details dazu unter [[1]](https://github.com/karolpiczak/ESC-50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Auslesen der Datenbank\n",
    "#\n",
    "df = pd.read_csv( localExtractionFolder + '/ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige als PCM Kurven\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features (file, hop, bins):\n",
    "    \n",
    "    y = np.zeros(sampleLen);   \n",
    "    yt, sr = librosa.core.load  (file, mono=True)\n",
    "    \n",
    "    if len(yt) == 0: \n",
    "        print ('found empty file ' + file )\n",
    "        return 0\n",
    "\n",
    "    min_length = min(len(y), len(yt))\n",
    "    y[:min_length] = yt[:min_length]\n",
    "    \n",
    "    C = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop, n_mfcc = bins)  \n",
    "    #print('mfcc {}'.format(C) )\n",
    "        \n",
    "    return C\n",
    "\n",
    "memory = joblib.Memory(cachedir=localExtractionFolder+'/esc50_joblib', verbose=0)\n",
    "cached_get_features = memory.cache(get_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_features (root_path):\n",
    "    \n",
    "    hop = 2048\n",
    "    bins = 100\n",
    "        \n",
    "    classes = 50\n",
    "    samples = 0\n",
    "\n",
    "    y_data = []    \n",
    "    X_data = []\n",
    "    \n",
    "    for root, dir, files in os.walk(root_path):\n",
    "        \n",
    "        waves = fnmatch.filter(files, \"*.wav\")\n",
    "\n",
    "        if len(waves) != 0:\n",
    "            for item in waves:\n",
    "                # e.g. 2-39443-A-19.wav\n",
    "                fileName = os.path.splitext ( os.path.basename(item) )[0] \n",
    "                classID = int(fileName.split('-')[3])\n",
    "                \n",
    "                mfcc = cached_get_features( os.path.join(root, item), hop, bins)\n",
    "                print(\".\",end='')\n",
    "\n",
    "                X_data.append(mfcc)\n",
    "                y_data.append(classID)\n",
    "                \n",
    "                samples = samples + 1\n",
    "                if samples >= 1000:\n",
    "                    break\n",
    "    \n",
    "    X_data = np.stack(X_data, axis=2)\n",
    "    X_data = np.transpose(X_data, (2,0,1))\n",
    "    d1 = X_data.shape[0]\n",
    "    d2 = X_data.shape[1]\n",
    "    d3 = X_data.shape[2]    \n",
    "    X_data = np.reshape(X_data, (d1,d2,d3,1))\n",
    "    y_data = np.array(y_data)    \n",
    "\n",
    "    print (\"samples = \" + str (samples))\n",
    "\n",
    "    return X_data, y_data, classes, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 54, 1000)\n",
      "(1000, 100, 54)\n",
      "(1000, 100, 54, 1)\n",
      "(1000,)\n",
      "classes = 50\n",
      "samples = 1000\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data, classes, samples = compute_features (\"data/ESC-50/ESC-50-master/audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.astype('float32')\n",
    "y_data = y_data.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzeige als Bild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize (x):\n",
    "    mu = np.mean (x, axis=0)\n",
    "    de = np.std (x, axis=0)\n",
    "    \n",
    "    eps = np.finfo('float32').eps\n",
    "    x = (x - mu) / (eps + de)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = standardize(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_data = np_utils.to_categorical(y_data, classes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train und Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (750, 100, 54, 1) (250, 100, 54, 1) (750, 50) (250, 50)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Split der Daten in Train und Test(validation) Datensätze\n",
    "#\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print('shapes {} {} {} {}'.format(x_train.shape, x_validation.shape, y_train.shape, y_validation.shape ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model bauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen eines einfache Modelles\n",
    "#\n",
    "def createModel():\n",
    "    \n",
    "    img_rows = x_train.shape[1]\n",
    "    img_cols = x_train.shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, kernel_size=5, strides=1, border_mode='same', input_shape=(img_rows, img_cols, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, kernel_size=3, strides=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "     \n",
    "    model.add(Convolution2D(64, kernel_size=3, strides=1, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, kernel_size=3, strides=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 100, 54, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 100, 54, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 98, 52, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 98, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 49, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 49, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 49, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 49, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 47, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 47, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 23, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               9044480   \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 9,135,634\n",
      "Trainable params: 9,135,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = createModel()\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "optimizer = Adam ()\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.4,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.4,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto'), History()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 3.7168 - accuracy: 0.0613 - val_loss: 3.7558 - val_accuracy: 0.0560\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 16s 676ms/step - loss: 3.6143 - accuracy: 0.0780 - val_loss: 3.6265 - val_accuracy: 0.0600\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 16s 688ms/step - loss: 3.5018 - accuracy: 0.0965 - val_loss: 3.5193 - val_accuracy: 0.0920\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 15s 631ms/step - loss: 3.3855 - accuracy: 0.1171 - val_loss: 3.5685 - val_accuracy: 0.0920\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 15s 632ms/step - loss: 3.3303 - accuracy: 0.1295 - val_loss: 3.4797 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 15s 633ms/step - loss: 3.2970 - accuracy: 0.1518 - val_loss: 3.3003 - val_accuracy: 0.1240\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 14s 601ms/step - loss: 3.2562 - accuracy: 0.1295 - val_loss: 3.3129 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 3.1764 - accuracy: 0.1522 - val_loss: 3.3544 - val_accuracy: 0.1120\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 14s 606ms/step - loss: 3.1023 - accuracy: 0.1727 - val_loss: 3.2702 - val_accuracy: 0.1200\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 14s 614ms/step - loss: 3.1301 - accuracy: 0.1657 - val_loss: 3.2661 - val_accuracy: 0.1280\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 14s 621ms/step - loss: 3.0564 - accuracy: 0.1630 - val_loss: 3.1138 - val_accuracy: 0.1600\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 14s 611ms/step - loss: 3.0705 - accuracy: 0.1871 - val_loss: 3.3039 - val_accuracy: 0.1600\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 14s 619ms/step - loss: 2.9371 - accuracy: 0.2011 - val_loss: 3.0003 - val_accuracy: 0.1600\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 3.0207 - accuracy: 0.1964 - val_loss: 3.0620 - val_accuracy: 0.1440\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 14s 613ms/step - loss: 3.0154 - accuracy: 0.1783 - val_loss: 3.3531 - val_accuracy: 0.1320\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 14s 605ms/step - loss: 2.9374 - accuracy: 0.2029 - val_loss: 3.1606 - val_accuracy: 0.1760\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 14s 616ms/step - loss: 2.8300 - accuracy: 0.2351 - val_loss: 3.0945 - val_accuracy: 0.1880\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x162b34e48>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit_generator(datagen.flow(x_train, y_train,\n",
    "                            batch_size=32),\n",
    "                            samples_per_epoch=x_train.shape[0],\n",
    "                            nb_epoch=20,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
