{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header_profi.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise GAN generated training data for MNIST classification \n",
    "\n",
    "The goal of this exercise is to evaluate the idea to generate additional trainings data for situations where either classes are imbalanced or some classes perform worse than others. The idea is e.g. described in [2].\n",
    "First a basic GAN is trained and some examples are generated. Then a GAN for controlled generation of samples is implemented and samples are generated. Those samples are added to the training data of a simple MNIST classifier. The performence with and without the generated training data is evaluated. \n",
    "\n",
    "The sources of the first version of the GAN is borrowed from the great Jason Brownlee tutorial at [1]. \n",
    "\n",
    "- [1] https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
    "- [2] https://arxiv.org/abs/1810.10863\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.datasets import mnist\n",
    "# source: https://github.com/tensorflow/tensorflow/issues/35407\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress some warnings\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU support\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'results/15_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic GAN\n",
    "\n",
    "First lets play with a basic GAN implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator and discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    #opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    opt = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    # upsample to 14x14\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add the discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    #opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    opt = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generating and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare mnist training images\n",
    "def load_real_samples():\n",
    "    # load mnist dataset\n",
    "    (trainX, _), (_, _) = load_data()\n",
    "    # expand to 3d, e.g. add channels dimension\n",
    "    X = expand_dims(trainX, axis=-1)\n",
    "    # convert from unsigned ints to floats\n",
    "    X = X.astype('float32')\n",
    "    # scale from [0,255] to [0,1]\n",
    "    X = X / 255.0\n",
    "    return X\n",
    " \n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and quality results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = prefix + 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "\n",
    "# plot performance and save model    \n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100, save_model=False):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('accuracy real: {:.3f}, fake: {:.3f}'.format(acc_real, acc_fake))\n",
    "    \n",
    "    # save plot\n",
    "    save_plot(x_fake, epoch)\n",
    "    \n",
    "    if save_model:\n",
    "        # save the generator model tile file\n",
    "        filename = prefix + 'generator_model_%03d.h5' % (epoch + 1)\n",
    "        g_model.save(filename)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256,debug=False):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        print(\".\",end='')\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            \n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            \n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            \n",
    "            # create mixed training set for the discriminator\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "\n",
    "            # update discriminator model weights\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            \n",
    "            # create inverted labels for the fake samples !!!!\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            \n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "            # summarize loss on this batch\n",
    "            if debug:\n",
    "                print('epoch %d, %d/%d, discriminator loss = {:.3f}, generator loss = {:.3f}'.format (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "        \n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(\"+\")\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim, save_model=False)\n",
    "\n",
    "    # final summary and model\n",
    "    summarize_performance(i, g_model, d_model, dataset, latent_dim, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 15\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example digits\n",
    "\n",
    "After training the model, generate some example digits using the GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the generator model and generating images\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    " \n",
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot(examples, n):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model(prefix+'generator_model_100.h5')\n",
    "# generate images\n",
    "latent_points = generate_latent_points(latent_dim, 25)\n",
    "# generate images\n",
    "X = model.predict(latent_points)\n",
    "# plot the result\n",
    "save_plot(X, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples of a specific class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: InfoGAN and ACGAN\n",
    "\n",
    "It seems that the images produced by the vanilla GAN start to converge after very long training. However, there is still the question open, how do we create selected digits using the generator model. Here, more advanced GAN types come into place. \n",
    "\n",
    "An immediate candidate would be the InfoGAN, this GAN type splits the generator input into a stochastic part and into a latent space vector with controlled semantics. This is what we want. A latent vector to control our desired output. However, it is still unclear, what the dimensions in the latent vector mean.\n",
    "\n",
    "Another type of advanced GAN is the Conditional GAN. It works with the same idea, but the latent space is basically the label of the digit. So there we have a direct control over which digit we generate. So, our next step is to implement a special type of conditional GAN called ACGAN. Select one of [6],[7] or [8] sources for your implementation. Source [6] worked reasonable well.\n",
    "\n",
    "**Notes**\n",
    "- Start with a latent dim size of 25.\n",
    "- Store your trained model using keras model.save method (acgan_generator.h5)\n",
    "- Make sure that the generator model can later be used for sampling examples. Take a look at the next task, how the model is used there for sampling.\n",
    "\n",
    "\n",
    "[5] https://machinelearningmastery.com/how-to-develop-an-information-maximizing-generative-adversarial-network-infogan-in-keras/\n",
    "\n",
    "[6] https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py\n",
    "\n",
    "[7] https://github.com/lukedeo/keras-acgan/blob/master/mnist_acgan.py\n",
    "\n",
    "[8] https://keras.io/examples/mnist_acgan/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example taken from https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py\n",
    "\n",
    "\n",
    "class ACGAN():\n",
    "    \n",
    "    def __init__(self,latent_dim=25):\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=losses,optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid, target_label = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model([noise, label], [valid, target_label])\n",
    "        self.combined.compile(loss=losses, optimizer=optimizer)\n",
    "\n",
    "        \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Extract feature representation\n",
    "        features = model(img)\n",
    "\n",
    "        # Determine validity and label of the image\n",
    "        validity = Dense(1, activation=\"sigmoid\")(features)\n",
    "        label = Dense(self.num_classes, activation=\"softmax\")(features)\n",
    "        return Model(img, [validity, label])\n",
    "\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure inputs\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            #  Train Discriminator\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # The labels of the digits that the generator tries to create an\n",
    "            # image representation of\n",
    "            sampled_labels = np.random.randint(0, 10, (batch_size, 1))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "            # Image labels. 0-9 \n",
    "            img_labels = y_train[idx]\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, [valid, img_labels])\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, sampled_labels])\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            \n",
    "            #  Train Generator\n",
    "\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if (epoch) % sample_interval == 0:\n",
    "                self.save_model()\n",
    "                self.sample_images(epoch,count)\n",
    "                count = count + 1\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch, count):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig( prefix + \"image_%06d.png\" % count )\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "    def save_model(self):\n",
    "        def save(model, model_name):\n",
    "            model_path = prefix + \"%s.json\" % model_name\n",
    "            weights_path = prefix + \"%s_weights.hdf5\" % model_name\n",
    "            options = {\"file_arch\": model_path,\n",
    "                        \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        def save_keras(model,name):\n",
    "            filename = prefix + 'acgan_' + name + '.h5'\n",
    "            model.save(filename)\n",
    "            \n",
    "        save_keras(self.generator, \"generator\")\n",
    "        save_keras(self.discriminator, \"discriminator\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: create the model and train it\n",
    "\n",
    "acgan = ACGAN(latent_dim=latent_dim)\n",
    "acgan.train(epochs=14000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples\n",
    "\n",
    "Use the trained and stored model to samples some example images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ACGAN model\n",
    "model = load_model(prefix+'acgan_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate some images using the model\n",
    "#\n",
    "def sample_images(model,count,digit,latent_dim):\n",
    "    noise = np.random.normal(0, 1, (count, latent_dim))\n",
    "    sampled_labels = np.array( [digit] * count )\n",
    "    \n",
    "    # use the generator model with random prior plus label values\n",
    "    gen_imgs = model.predict( [noise, sampled_labels] )\n",
    "    \n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(count)\n",
    "    for i in range(count):\n",
    "        axs[i].imshow(gen_imgs[i,:,:,0], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    fig.savefig( prefix + \"sample_image.png\" )\n",
    "    plt.close()\n",
    "    \n",
    "    sampled_labels = np.reshape(sampled_labels,(-1,1))\n",
    "    return gen_imgs, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new, y_train_new = sample_images(model,100,7,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_new.shape)\n",
    "print(y_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(x_train_new,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic MNIST classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mnist_model():\n",
    "    seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = build_mnist_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mnist_model.fit(x_train, y_train, batch_size=128, epochs=7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = mnist_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('accuracy {:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the worst class \n",
    "\n",
    "Find out which digit class has the most errors in classification. Print a histogram of errors for each class. You can also plot a confusion matrix of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: plot histogram of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot_errors(model):\n",
    "    errorCount = 0\n",
    "    errorCountDistribution = [0] * 10\n",
    "    for i in range(x_test.shape[0]):\n",
    "        correctClass = argmax(y_test[i])\n",
    "        image = x_test[i].reshape((1,28,28,1))\n",
    "        prediction = model.predict_classes([image])\n",
    "        predictedClass = prediction[0]\n",
    "        if predictedClass != correctClass:\n",
    "            errorCount+= 1\n",
    "            errorCountDistribution[correctClass] = errorCountDistribution[correctClass] + 1\n",
    "            \n",
    "    class_pos = np.arange(10)\n",
    "    plt.bar(class_pos, errorCountDistribution, align='center', alpha=0.5)\n",
    "    plt.xlabel(class_pos)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Error count per digit class')\n",
    "    plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_errors(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: the worst class is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended training set with samples of the worst class \n",
    "\n",
    "Now, since we know the worst class, we can go back to the ACGAN and generate some samples (e.g. 100) of this class and add them to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ext = np.concatenate([x_train, x_train_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = to_categorical(y_train_new, num_classes=10)\n",
    "y_train_ext = np.concatenate([y_train, y_train_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model2 = build_mnist_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mnist_model2.fit(x_train_ext, y_train_ext, batch_size=128, epochs=7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of new model\n",
    "\n",
    "Measure the performance of the new model and discuss the results. Has it gotten any better? Could it be that the improvement is smaller than the variance of the accuracy? Try several runs! What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = mnist_model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('accuracy {:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_errors(mnist_model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
