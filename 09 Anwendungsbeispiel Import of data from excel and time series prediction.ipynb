{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Import of excel data and timeseries prediction\n",
    "\n",
    "Das Ziel dieses Beispieles ist es die Arbeit mit Zeitreihen aus Excel Files zu zeigen und darauf ein Vorhersagemodell für Zeitreihen zu entwickeln. Der Datensatz beschreibt die Entwicklung von Flugpassagierzahlen einer Airline in der fernen Vergangenheit. Die Daten sind aber typisch für Daten wie sie KMUs (z.B. Verkaufszahlen) zu finden sind. \n",
    "\n",
    "\n",
    "Der Code für das Beispiel wurde aus [1] adaptiert. Weitergehende Informationen sind zum Beispiel in [2] zu finden. \n",
    "\n",
    "- [1] [https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)\n",
    "- [2] [https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa](https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa)\n",
    "\n",
    "\n",
    "Zitierung Datensatz:\n",
    "```\n",
    "Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import der Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import der Module\n",
    "#\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Abdrehen von Fehlermeldungen\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Für GPU Support\n",
    "#\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Konstanten für Dateien\n",
    "#\n",
    "excelData = 'data/airline_passengers.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.ExcelFile(excelData)\n",
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Auslesen eines Tabellenblattes\n",
    "#\n",
    "df = data.parse('Tabellenblatt1')\n",
    "df.info\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausschneiden von Daten in pandas dataframes\n",
    "\n",
    "Ein sehr gutes Tutorial dazu kann hier gefunden werden: [https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/](https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/)\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Ausschneiden der benötigten Daten\n",
    "#\n",
    "df_cut = df.iloc[3:146,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.columns = ['month','passengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut['passengers'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konventionelle Arbeit mit solchen Zeitreihen\n",
    "\n",
    "Es gibt eine Reihe von älteren Methoden um mit solchen Zeitreihen umzugehen und auch gute Ergebnisse bei der Vorhersage zu erreichen. Beispiele dazu sind hier zu finden:\n",
    "\n",
    "- https://machinelearningmastery.com/time-series-trends-in-python/\n",
    "- https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa\n",
    "\n",
    "\n",
    "Die wesentliche Leistung dieser Verfahren ist die Berechnung und Verwendung von Parameters wie **Trend** und **Saisonalität**. Wir hoffen, dass unsere Modelle damit umgehen können, ohne dass wir uns explizit darum kümmern müssen.\n",
    "\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_cut['passengers'].values\n",
    "x_data = x_data.astype('float32')\n",
    "x_data = np.reshape(x_data,(-1,1))\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalize the dataset\n",
    "#\n",
    "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "scaler.fit(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = scaler.transform(x_data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(x_data) * 0.80)\n",
    "test_size = len(x_data) - train_size\n",
    "train, test = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen eines Trainingsdatensatzes mit Hilfe von sliding windows\n",
    "\n",
    "Sliding windows werden aus einer Zeitreihe erzeugt, indem ein Fenster über die gesamte Zeitreihe gezogen wird und dabei jeweils die Daten im Fenster kopiert werden. Mehr Details dazu hier [https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe](https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe).\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformation einer Zeitreihe in sliding windows mit einem label (y)\n",
    "#\n",
    "def createSlidingWindowsWithLabel(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[ i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anwenden der sliding window Funktion\n",
    "#\n",
    "look_back = 1\n",
    "trainX, trainY = createSlidingWindowsWithLabel(train, look_back)\n",
    "testX, testY = createSlidingWindowsWithLabel(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# reshape input to be [samples, time steps, features]\n",
    "#\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create and fit the LSTM network\n",
    "#\n",
    "def createLSTMModel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = createLSTMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model.fit(trainX, trainY, epochs=40, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Schätzung der Werte für train und test Daten\n",
    "#\n",
    "trainPredict = lstm_model.predict(trainX)\n",
    "testPredict = lstm_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Rücktransformation der Schätzungen (scaler)\n",
    "#\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainYi = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testYi = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige der geschätzten neuen Werte\n",
    "#\n",
    "plt.plot(testYi[0,0:])\n",
    "plt.plot(testPredict[1:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainYi[0,0:-1], trainPredict[1:,0]))\n",
    "print('train loss: %.3f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testYi[0,0:-1], testPredict[1:,0]))\n",
    "print('test loss: %.3f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(x_data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[:len(trainPredict)+0, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(x_data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2):len(x_data)-2, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(x_data), color='grey')\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbesserung durch Verwendung von Zusatzinformation in den Daten\n",
    "\n",
    "**Idee**: In dem Datensatz stecken mehr Informationen als wir bisher verwendet haben. Zum Beispiel das Monat eines Jahres sowie das Jahr. Wir können den Datensatz um diese Information anreichern um dem Modell mehr Informationen zu geben. Diese zusätzlich Information können wir aus dem Datumsfeature in den Originaldaten ableiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut['date'] = pd.to_datetime(df_cut['month'], infer_datetime_format=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut['year'] = pd.DatetimeIndex(df_cut['date']).year\n",
    "df_cut['month'] = pd.DatetimeIndex(df_cut['date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_raw = df_cut.loc[:, ['month', 'passengers','year']].values\n",
    "print(x_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data_raw.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.reshape(x_data,(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalize the dataset\n",
    "#\n",
    "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "scaler.fit(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_scaled = scaler.transform(x_data)\n",
    "print(x_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformation einer multivariaten Zeitreihe in sliding windows mit einem label (y)\n",
    "#\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('x%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('y%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('y%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen der Windows für Vorhersage\n",
    "#\n",
    "windowSize = 12\n",
    "x_data_windowed = series_to_supervised(x_data_scaled, windowSize, 1)\n",
    "print(x_data_windowed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Löschen der Labels, die nicht geschätzt werden sollen (month, year)\n",
    "#\n",
    "\n",
    "x_data_windowed.drop(x_data_windowed.columns[[windowSize*3,(windowSize*3)+2]], axis=1, inplace=True)\n",
    "print(x_data_windowed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data_windowed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "x_data = x_data_windowed.values\n",
    "train_size = int(len(x_data) * 0.70)\n",
    "test_size = len(x_data) - train_size\n",
    "train, test = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Trennen in features und labels\n",
    "#\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Form anpassen für Modell\n",
    "#\n",
    "train_X_r = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X_r = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X_r.shape, train_y.shape, test_X_r.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create and fit the LSTM network\n",
    "#\n",
    "def createMVLSTMModel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, dropout=0.1, input_shape=(train_X_r.shape[1], train_X_r.shape[2])))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = createMVLSTMModel()\n",
    "history = model.fit(train_X_r, train_y, epochs=300, batch_size=24, validation_data=(test_X_r, test_y), verbose=1, shuffle=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Berechung der Vorhersagen\n",
    "#\n",
    "yhat = model.predict(test_X_r,batch_size=1)\n",
    "trainyhat = model.predict(train_X_r,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertForecastScaling(x,y):\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = np.concatenate( ( x[:,0:1], y[:,:], x[:, 0:1] ), axis=1 )\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,1]\n",
    "    return inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = invertForecastScaling(test_X,yhat)\n",
    "print(inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y = invertForecastScaling(test_X,test_y.reshape(-1,1))\n",
    "print(inv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inv_yhat,color='b')\n",
    "plt.plot(inv_y,color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "testScore = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test loss: %.3f RMSE' % testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_train = invertForecastScaling(train_X,trainyhat.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(x_data_raw[:,1])\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[windowSize:len(inv_y_train)+windowSize] = inv_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(x_data_raw[:,1])\n",
    "testPredictPlot[:] = np.nan\n",
    "testPredictPlot[len(x_data_raw)-len(inv_yhat):len(x_data_raw)] = inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(x_data_raw[:,1])\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welche Verbesserungsschritte wären sonst noch möglich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
