{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Classification with CNN (MNIST)\n",
    "\n",
    "\n",
    "Das Ziel des Beispieles ist es handschriftliche Ziffern zu klassifizieren.\n",
    "Dazu verwenden wir den MNIST Datensatz [1]. Dieser Datensatz enthält 60.000 Scans von Ziffern zum Trainieren und 10.000 Scans von Ziffern für die Validierung. Ein Sample besteht aus 28x28 Features mit Werten zwischen 0 und 255. Zu beachten ist, dass die Features invertiert sind. Eigentlich sind Ziffern eher dunkel auf hellem Hintergrund. MNIST Ziffern sind hell auf dunklem Hintergrund.\n",
    "\n",
    "Dieses Beispiel beruht auf einem Tutorial von Jason Brownlee [2] mit Hinweisen auf die Optimierung aus [3].\n",
    "\n",
    "```\n",
    "[1] http://yann.lecun.com/exdb/mnist/\n",
    "[2] https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
    "[3] https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Importieren der Module\n",
    "#\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "# Abdrehen von Fehlermeldungen\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "#\n",
    "# Einstellen der Grösse von Diagrammen\n",
    "#\n",
    "plt.rcParams['figure.figsize'] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereiten der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Beispieldaten (hier sehr vereinfacht) und gleichzeitige Aufteilung in Trainings- und Testdaten\n",
    "#\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige der Anzahl und Form der Samples\n",
    "#\n",
    "print('Trainingsdaten: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Testdaten: X=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige von Beispielen der Daten\n",
    "#\n",
    "for i in range(15):\n",
    "    plt.subplot(4,4,1 + i)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige der Labels zu den Daten\n",
    "#\n",
    "for i in range(15):\n",
    "    print('label {}'.format(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Histogramm der Klassen (Ziffern)\n",
    "#\n",
    "#\n",
    "# Prüfen der Verteilung der Klassen\n",
    "#\n",
    "df = pd.DataFrame(y_train,columns=['class'])\n",
    "counts= df.groupby('class').size()\n",
    "\n",
    "class_pos = np.arange(10)\n",
    "plt.bar(class_pos, counts, align='center', alpha=0.5)\n",
    "plt.xlabel(class_pos)\n",
    "plt.ylabel('Ziffern')\n",
    "plt.title('Samples pro Ziffer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Ändere die Matrixform der Daten\n",
    "#\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Ändere Pixelwerte von 0..255 auf einen Wert zwischen 0 und 1 in Flieskommaform\n",
    "#\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Ändere die Zielwerte für die Klassifizierung (eine Vektorstelle pro Klasse)\n",
    "#\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstes Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Aufbau eines CNN Modelles mit einer CNN Schicht\n",
    "#\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Messen der Accuracy\n",
    "#\n",
    "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy {:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Abschätzen der Fehler im Einsatz\n",
    "#\n",
    "print('Bei {} Samples sind rund {:.0f} Fehler zu erwarten.'.format( x_test.shape[0], (x_test.shape[0]*(1-acc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbesserung des Modelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Definition eines verbesserten Modelles mit folgenden Änderungen\n",
    "# 1) weiterer convolutional layer\n",
    "# 2) Vergrößerung der Filter\n",
    "# 3) Vergrößerung des fully connected layers auf 256\n",
    "# 4) Verlängerung des Trainings\n",
    "#\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model2.add(Conv2D(64, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(x_train, y_train, batch_size=64, epochs=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Messen der Accuracy\n",
    "#\n",
    "_, acc = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy {:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Abschätzen der Fehler im Einsatz\n",
    "#\n",
    "print('Bei {} Samples sind rund {:.0f} Fehler zu erwarten.'.format( x_test.shape[0], (x_test.shape[0]*(1-acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Ausgabe des Trainingsverlaufes\n",
    "#\n",
    "def summarize_diagnostics(history,modelname):\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.savefig( 'results/' + modelname + '_plot.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(history,'04_model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speichern des Modelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Speichern des Modelles für später\n",
    "#\n",
    "from keras.models import model_from_json\n",
    "\n",
    "prefix = 'results/04_'\n",
    "modelName = prefix + \"model.json\"\n",
    "weightName = prefix + \"model.h5\"\n",
    "\n",
    "# auf True setzen, wenn das neue Modell vollständig trainiert wurde\n",
    "if False:\n",
    "    model_json = model2.to_json()\n",
    "    with open( modelName , \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model2.save_weights( weightName )\n",
    "    print(\"saved model to disk as {} {}\".format(modelName,weightName))\n",
    "\n",
    "    \n",
    "# auf True setzen, wenn das neue Modell nur geladen werden soll (vorher gespeichert, ist nicht im git)    \n",
    "if True:\n",
    "    json_file = open(modelName, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weightName)\n",
    "    print(\"loaded model from disk\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des Modelles und Untersuchung der Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige von Beispielen der Daten die fehlschlagen\n",
    "#\n",
    "from numpy import argmax\n",
    "\n",
    "plotCount = 0\n",
    "errorCount = 0\n",
    "errorCountDistribution = [0] * 10\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Predicted vs True Class')\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    \n",
    "    correctClass = argmax(y_test[i])\n",
    "    image = x_test[i].reshape((1,28,28,1))\n",
    "    prediction = model2.predict_classes([image])\n",
    "    predictedClass = prediction[0]\n",
    "    \n",
    "    if predictedClass != correctClass:\n",
    "        \n",
    "        errorCount+= 1\n",
    "        errorCountDistribution[correctClass] = errorCountDistribution[correctClass] + 1\n",
    "        \n",
    "        if plotCount < 9:\n",
    "            ax = plt.subplot(330 + 1 + plotCount)\n",
    "            ax.set_title('{}!={}'.format ( str(predictedClass), str(correctClass)))     \n",
    "            image = x_test[i].reshape((28,28))\n",
    "            plt.imshow(image, cmap=plt.get_cmap('gray'))    \n",
    "            plotCount+= 1\n",
    "        \n",
    "\n",
    "plt.subplots_adjust(wspace=0.4,hspace=0.4)\n",
    "plt.show()\n",
    "print('Anzahl der gefundenen Fehler ist {}'.format(errorCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pos = np.arange(10)\n",
    "plt.bar(class_pos, errorCountDistribution, align='center', alpha=0.5)\n",
    "plt.xlabel(class_pos)\n",
    "plt.ylabel('Ziffern')\n",
    "plt.title('Fehler pro Ziffer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testen mit eigenen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Laden weiterer Funktionen\n",
    "#\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für das Laden eines Bildes aus einer Datei\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, color_mode = \"grayscale\", target_size=(28, 28))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 1 channel\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden eines eigenen Bildes mit einer Ziffer (2,3,8,9)\n",
    "#\n",
    "image = load_image('data/3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anzeige\n",
    "#\n",
    "imageShow = image.reshape((28,28))\n",
    "plt.imshow(imageShow, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict_classes([image])\n",
    "predictedClass = prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Die geschätzte Ziffer ist {}'.format(predictedClass) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('confidence {:.4f}'.format(prediction[0][3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
