{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Import of image data with augmentation and classification\n",
    "\n",
    "Das Ziel dieses Beispieles ist es die Organisation, den Import und die Vorbereitung von Bilddaten für eine Klassifikation zu erklären. Dabei werden folgende Schritte durchgeführt:\n",
    "\n",
    "- Dynamisches Laden und entpacken der Bilddaten von einer externen Quelle\n",
    "- Review der Organisation auf dem Filesystem\n",
    "- Laden der Daten\n",
    "- Transformationen\n",
    "- Augmentierung\n",
    "- Training\n",
    "- Analyse\n",
    "- Verbesserung\n",
    "\n",
    "Der verwendete Datensatz heisst caltech101[3] mit 101 Klassen und jeweils 40 bis 800 Bildern pro Klasse. Die Bilder haben 200 - 300 Pixel Auflösung in Farbe.\n",
    "\n",
    "Quellen für die Beispiele und Daten:\n",
    "\n",
    "- [1] [https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)\n",
    "- [2] [https://github.com/bhavul/Caltech-101-Object-Classification](https://github.com/bhavul/Caltech-101-Object-Classification)\n",
    "- [3] [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import der Module\n",
    "#\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import tarfile\n",
    "import operator\n",
    "import random\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Für GPU Support\n",
    "#\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDataSource = 'http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz'\n",
    "localExtractionFolder = 'data/caltech101'\n",
    "localDataArchive = 'data/caltech101/caltech101.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Daten von einer URL\n",
    "#\n",
    "def download_dataset(url,dataset_file_path):\n",
    "    if os.path.exists(localDataArchive):\n",
    "        print(\"archive already downloaded.\")\n",
    "    else:\n",
    "        print(\"started loading archive from url {}\".format(url))\n",
    "        filename, headers = urlretrieve(url, dataset_file_path)\n",
    "        print(\"finished loading archive from url {}\".format(url))\n",
    "\n",
    "def extract_dataset(dataset_file_path, extraction_directory):\n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)\n",
    "    if (dataset_file_path.endswith(\"tar.gz\") or dataset_file_path.endswith(\".tgz\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:gz\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    elif (dataset_file_path.endswith(\"tar\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Daten ausführen\n",
    "#\n",
    "download_dataset(urlDataSource,localDataArchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Extrahieren der Daten\n",
    "#\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation von Bilddaten auf dem Filesystem\n",
    "\n",
    "Eine gute Einführung in das Thema ist zu finden unter\n",
    "\n",
    "- [Brownlee](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/) \n",
    "- [Sarkar](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hilfsfunktionen\n",
    "#\n",
    "\n",
    "def get_images(object_category, data_directory):\n",
    "    if (not os.path.exists(data_directory)):\n",
    "        print(\"data directory not found.\")\n",
    "        return\n",
    "    obj_category_dir = os.path.join(os.path.join(data_directory,\"101_ObjectCategories\"),object_category)\n",
    "    images = [os.path.join(obj_category_dir,img) for img in os.listdir(obj_category_dir)]\n",
    "    return images\n",
    "\n",
    "def return_images_per_category(data_directory):\n",
    "    folder = os.path.join(data_directory,\"101_ObjectCategories\")\n",
    "    #print(folder)\n",
    "    categories=[d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder,d))]\n",
    "    #print(categories)\n",
    "    return categories\n",
    "\n",
    "#\n",
    "# Lesen der Bilddaten aus einer Datei. Anpassen der Größe auf 300x200 (Breite x Höhe) Pixel.\n",
    "#\n",
    "def read_image(image_path):\n",
    "    #img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #img = cv2.resize(img, (300,200), interpolation=cv2.INTER_CUBIC)    \n",
    "    im = Image.open(image_path).convert(\"RGB\").resize((300,200))\n",
    "    np_img = np.array(im)\n",
    "    return np_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_training_data(data_directory,fraction):\n",
    "    \n",
    "    i = 0\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    print(\"started to read dataset from {}.\".format(data_directory) )\n",
    "    \n",
    "    for category in return_images_per_category(data_directory):\n",
    "        \n",
    "        if category == 'BACKGROUND_Google':\n",
    "            continue\n",
    "        \n",
    "        print(\".\",end='')\n",
    "        \n",
    "        for image in get_images(category, data_directory):\n",
    "            if not image.endswith('.jpg'):\n",
    "                continue\n",
    "                \n",
    "            if random.uniform(0, 1) > fraction:\n",
    "                continue\n",
    "                \n",
    "            X.insert(i, read_image(image) )\n",
    "            Y.insert(i, category )\n",
    "            i += 1\n",
    "    print(\"finished reading dataset.\")\n",
    "    X = np.array(X)\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen der Trainingsdaten\n",
    "#\n",
    "X, Y = create_training_data(localExtractionFolder,0.4)\n",
    "\n",
    "print('data X={}, y={}'.format(X.shape, len(Y)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformation der Labels in one-hot encoding\n",
    "#\n",
    "label_encoder = LabelEncoder()\n",
    "Y_integer_encoded = label_encoder.fit_transform(Y)\n",
    "Y_one_hot = to_categorical(Y_integer_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalisieren der Bilddaten\n",
    "#\n",
    "X_normalized = ( X.astype(np.float64) / 255 ) + 0.001\n",
    "\n",
    "\n",
    "#\n",
    "# Löschen von X um Speicher gezielt freizumachen\n",
    "#\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split der Daten in Train und Test(validation) Datensätze\n",
    "#\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_normalized, Y_one_hot, test_size=0.25, random_state=42)\n",
    "del X_normalized\n",
    "\n",
    "\n",
    "#\n",
    "# gültige Werte in X_train, X_validation, Y_train, Y_validation, label_encoder, data_directory\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prüfen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Form der Daten\n",
    "#\n",
    "print('train: X=%s, y=%s' % (X_train.shape, Y_train.shape))\n",
    "print('test: X=%s, y=%s' % (X_validation.shape, Y_validation.shape))\n",
    "\n",
    "#\n",
    "# Plot von Bildern\n",
    "#\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen eines einfache Modelles\n",
    "#\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', input_shape=(200,300,3)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(101, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compile und Training des Modelles\n",
    "#\n",
    "\n",
    "model_cnn = createModel()\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [ModelCheckpoint('model_cnn_weights.h5', monitor='val_acc', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')]\n",
    "\n",
    "history = model_cnn.fit(X_train, Y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_validation,Y_validation), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluierung des Modelles\n",
    "#\n",
    "_, acc = model_cnn.evaluate(X_validation, Y_validation, verbose=0)\n",
    "print('accuracy {:.3f} '.format(acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Ausgabe des Trainingsverlaufes\n",
    "#\n",
    "def summarize_diagnostics(history,modelname):\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='green', label='test')\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='green', label='test')\n",
    "    pyplot.subplots_adjust(hspace=0.5)\n",
    "    pyplot.savefig( 'results/' + modelname + '_plot.png')\n",
    "    pyplot.show()\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(history,'model_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiertes Laden der Bilder\n",
    "\n",
    "Die bisherige Ladefunktion hat alle Bilder in den Speicher geladen. Das führt schnell dazu, dass der Hauptspeicher ausgeht. Daher benötigen wir eine Funktion, die Bilder der Reihe nach in den Speicher lädt und für das Training zur Verfügung stellt.\n",
    "\n",
    "Eine solche Funktion kann mit einem python **Generator** implementiert werden. Die Erklärung von Generatoren ist hier zu finden [2]. Das Tutorial zum Laden mit Generatoren ist hier [1] zu finden.\n",
    "\n",
    "Quellen:\n",
    "- [1][https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)\n",
    "- [2] [https://www.python-kurs.eu/generatoren.php](https://www.python-kurs.eu/generatoren.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anlegen eines Generators für Bilder\n",
    "#\n",
    "datagen = ImageDataGenerator()\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(X_train, Y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training\n",
    "#\n",
    "\n",
    "model_cnn = createModel()\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#\n",
    "# Neue Funktion fit_generator\n",
    "#\n",
    "steps = int(X_train.shape[0] / 64)\n",
    "history = model_cnn.fit_generator(it_train, steps_per_epoch=steps, epochs=10, validation_data=(X_validation,Y_validation), verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluierung\n",
    "#\n",
    "_, acc = model_cnn.evaluate(X_validation, Y_validation, verbose=0)\n",
    "print('accuracy {:.3f} '.format(acc) )\n",
    "summarize_diagnostics(history,'model_cnn_gen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierung durch Augmentierung\n",
    "\n",
    "Augmentierung erweitert den Trainingsdatensatz um künstlich erzeugte Bilder. Damit wird erreicht, dass ein Modell robuster wird und sich nicht auf einzelne Pixel bezieht. Methoden der Augmentierung für Bilder sind:\n",
    "\n",
    "- Breite und Höhe des Bildinhaltes ändern (width_shift_range, height_shift_range)\n",
    "- Spiegelung (flip)\n",
    "- Rotation (rotation_range)\n",
    "- Zoomen (zoom_range)\n",
    "- Helligkeit (brightness_range)\n",
    "- Verzerrung (shear_range)\n",
    "\n",
    "Das Zufügen von Rauschen kann in Keras nicht direkt über den [ImageDataGenerator](https://keras.io/preprocessing/image/) eingestellt werden. Dies wird aber durch die Verwendung von Dropout annähernd simuliert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Anlegen eines Generators für Bilder\n",
    "#\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, rotation_range=10, zoom_range=0.1)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(X_train, Y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training\n",
    "#\n",
    "steps = int(X_train.shape[0] / 64)\n",
    "\n",
    "model_cnn = createModel()\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model_cnn.fit_generator(it_train, steps_per_epoch=steps, epochs=50, validation_data=(X_validation,Y_validation), verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluierung\n",
    "#\n",
    "_, acc = model_cnn.evaluate(X_validation, Y_validation, verbose=0)\n",
    "print('accuracy {:.3f} '.format(acc) )\n",
    "summarize_diagnostics(history,'model_cnn_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
