{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Import of image data with augmentation and classification\n",
    "\n",
    "Das Ziel dieses Beispieles ist es die Organisation, den Import und die Vorbereitung von Bilddaten für eine Klassifikation zu erklären. Dabei werden folgende Schritte durchgeführt:\n",
    "\n",
    "- Dynamisches Laden und entpacken der Bilddaten von einer externen Quelle\n",
    "- Review der Organisation auf dem Filesystem\n",
    "- Laden der Daten\n",
    "- Transformationen\n",
    "- Augmentierung\n",
    "- Training\n",
    "- Analyse\n",
    "- Verbesserung\n",
    "\n",
    "Der verwendete Datensatz heisst caltech101[3] mit 101 Klassen und jeweils 40 bis 800 Bildern pro Klasse. Die Bilder haben 200 - 300 Pixel Auflösung in Farbe.\n",
    "\n",
    "Quellen für die Beispiele und Daten:\n",
    "\n",
    "- [1] [https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)\n",
    "- [2] [https://github.com/bhavul/Caltech-101-Object-Classification](https://github.com/bhavul/Caltech-101-Object-Classification)\n",
    "- [3] [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import der Module\n",
    "#\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import tarfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hilfsfunktionen zum Zugriff auf die Bilder\n",
    "#\n",
    "\n",
    "def get_images(object_category, data_directory):\n",
    "    if (not os.path.exists(data_directory)):\n",
    "        print(\"Data directory not found. Are you sure you downloaded and extracted dataset properly?\")\n",
    "        return\n",
    "    obj_category_dir = os.path.join(os.path.join(data_directory,\"101_ObjectCategories\"),object_category)\n",
    "    images = [os.path.join(obj_category_dir,img) for img in os.listdir(obj_category_dir)]\n",
    "    return images\n",
    "\n",
    "def return_images_per_category(data_directory):\n",
    "    categories = os.listdir(data_directory+\"/101_ObjectCategories/\")\n",
    "    object_images_count_dict = {}\n",
    "    for category in categories:\n",
    "        object_images_count_dict[category] = len(os.listdir(data_directory+\"/101_ObjectCategories/\"+category))\n",
    "    object_images_count_dict = sorted(object_images_count_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return object_images_count_dict\n",
    "\n",
    "#\n",
    "# Lesen der Bilddaten aus einer Datei. Anpassen der Größe auf 300x200 (Breite x Höhe) Pixel.\n",
    "#\n",
    "def read_image(image_path):\n",
    "    #img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #img = cv2.resize(img, (300,200), interpolation=cv2.INTER_CUBIC)    \n",
    "    im = Image.open(image_path).resize((300,200))\n",
    "    np_img = numpy.array(im)\n",
    "    return np_img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Daten ausführen\n",
    "#\n",
    "\n",
    "download_dataset(urlDataSource)\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation von Bilddaten auf dem Filesystem\n",
    "\n",
    "Eine gute Einführung in das Thema ist zu finden bei Jason Brownlee unter [https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hilfsfunktion\n",
    "#\n",
    "def create_training_data(data_directory):\n",
    "    i = 0\n",
    "    X = np.ndarray((8677, 200, 300, 3), dtype=np.uint8)\n",
    "    Y = []\n",
    "    print(\"started to read dataset.\")\n",
    "    for category,_ in return_images_per_category(data_directory):\n",
    "        \n",
    "        if category == 'BACKGROUND_Google':\n",
    "            continue\n",
    "            \n",
    "        print(\"reading class {}\".format(category))\n",
    "        \n",
    "        for image in get_images(category, data_directory):\n",
    "            if not image.endswith('.jpg'):\n",
    "                continue\n",
    "            X[i] = read_image(image)\n",
    "            Y.insert(i,category)\n",
    "            i += 1\n",
    "        print(\"Images processed : \",i+1,\" of 8678\")\n",
    "    print(\"finished reading dataset.\")\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen der Trainingsdaten\n",
    "#\n",
    "X, Y = create_training_data(data_directory)\n",
    "\n",
    "\n",
    "#\n",
    "# Transformation der Labels in one-hot encoding\n",
    "#\n",
    "label_encoder = LabelEncoder()\n",
    "Y_integer_encoded = label_encoder.fit_transform(Y)\n",
    "Y_one_hot = to_categorical(Y_integer_encoded)\n",
    "\n",
    "\n",
    "#\n",
    "# Normalisieren der Bilddaten\n",
    "#\n",
    "X_normalized = ( X.astype(np.float64) / 255 ) + 0.001\n",
    "del X\n",
    "\n",
    "\n",
    "#\n",
    "# Split der Daten in Train und Test(validation) Datensätze\n",
    "#\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_normalized, Y_one_hot, test_size=0.25, random_state=42)\n",
    "del X_normalized\n",
    "\n",
    "#\n",
    "# gültige Werte in X_train, X_validation, Y_train, Y_validation, label_encoder, data_directory\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prüfen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Form der Daten\n",
    "#\n",
    "print('Train: X=%s, y=%s' % (X_train.shape, Y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (X_validation.shape, Y_validation.shape))\n",
    "\n",
    "#\n",
    "# Plot von Bildern\n",
    "#\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen eines einfache Modelles\n",
    "#\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(16, (3,3), activation='relu', input_shape=(200,300,3)))\n",
    "model_cnn.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model_cnn.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_cnn.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(101, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compile und Training des Modelles\n",
    "#\n",
    "\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [ModelCheckpoint('model_cnn_weights.h5', monitor='val_acc', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')]\n",
    "\n",
    "model_cnn.fit(X_train, Y_train, batch_size=64, epochs=30, verbose=1, validation_data=(X_validation,Y_validation), callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiertes Laden der Bilder\n",
    "\n",
    "Die bisherige Ladefunktion hat alle Bilder in den Speicher geladen. Das führt schnell dazu, dass der Hauptspeicher ausgeht. Daher benötigen wir eine Funktion, die Bilder der Reihe nach in den Speicher lädt und für das Training zur Verfügung stellt.\n",
    "\n",
    "Quelle: [https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
