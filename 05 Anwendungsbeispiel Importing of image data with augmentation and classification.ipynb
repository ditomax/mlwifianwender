{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel Import of image data with augmentation and classification\n",
    "\n",
    "Das Ziel dieses Beispieles ist es die Organisation, den Import und die Vorbereitung von Bilddaten für eine Klassifikation zu erklären. Dabei werden folgende Schritte durchgeführt:\n",
    "\n",
    "- Dynamisches Laden und entpacken der Bilddaten von einer externen Quelle\n",
    "- Review der Organisation auf dem Filesystem\n",
    "- Laden der Daten\n",
    "- Transformationen\n",
    "- Augmentierung\n",
    "- Training\n",
    "- Analyse\n",
    "- Verbesserung\n",
    "\n",
    "Der verwendete Datensatz heisst caltech101[3] mit 101 Klassen und jeweils 40 bis 800 Bildern pro Klasse. Die Bilder haben 200 - 300 Pixel Auflösung in Farbe.\n",
    "\n",
    "Quellen für die Beispiele und Daten:\n",
    "\n",
    "- [1] [https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)\n",
    "- [2] [https://github.com/bhavul/Caltech-101-Object-Classification](https://github.com/bhavul/Caltech-101-Object-Classification)\n",
    "- [3] [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/dietmar/opt/anaconda3/envs/wificlass/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Import der Module\n",
    "#\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import tarfile\n",
    "import operator\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDataSource = 'http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz'\n",
    "localExtractionFolder = 'data/caltech101'\n",
    "localDataArchive = 'data/caltech101/caltech101.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Laden der Daten von einer URL\n",
    "#\n",
    "def download_dataset(url,dataset_file_path):\n",
    "    if os.path.exists(localDataArchive):\n",
    "        print(\"archive already downloaded.\")\n",
    "    else:\n",
    "        print(\"started loading archive from url {}\".format(url))\n",
    "        filename, headers = urlretrieve(url, dataset_file_path)\n",
    "        print(\"finished loading archive from url {}\".format(url))\n",
    "\n",
    "def extract_dataset(dataset_file_path, extraction_directory):\n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)\n",
    "    if (dataset_file_path.endswith(\"tar.gz\") or dataset_file_path.endswith(\".tgz\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:gz\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    elif (dataset_file_path.endswith(\"tar\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Laden der Daten ausführen\n",
    "#\n",
    "download_dataset(urlDataSource,localDataArchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction of dataset from data/caltech101/caltech101.tar.gz to data/caltech101 done.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Extrahieren der Daten\n",
    "#\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation von Bilddaten auf dem Filesystem\n",
    "\n",
    "Eine gute Einführung in das Thema ist zu finden bei Jason Brownlee unter [https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erzeugen der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hilfsfunktionen\n",
    "#\n",
    "\n",
    "def get_images(object_category, data_directory):\n",
    "    if (not os.path.exists(data_directory)):\n",
    "        print(\"Data directory not found. Are you sure you downloaded and extracted dataset properly?\")\n",
    "        return\n",
    "    obj_category_dir = os.path.join(os.path.join(data_directory,\"101_ObjectCategories\"),object_category)\n",
    "    images = [os.path.join(obj_category_dir,img) for img in os.listdir(obj_category_dir)]\n",
    "    return images\n",
    "\n",
    "def return_images_per_category(data_directory):\n",
    "    folder = os.path.join(data_directory,\"101_ObjectCategories\")\n",
    "    print(folder)\n",
    "    categories=[d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder,d))]\n",
    "    print(categories)\n",
    "    return categories\n",
    "\n",
    "#\n",
    "# Lesen der Bilddaten aus einer Datei. Anpassen der Größe auf 300x200 (Breite x Höhe) Pixel.\n",
    "#\n",
    "def read_image(image_path):\n",
    "    #img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #img = cv2.resize(img, (300,200), interpolation=cv2.INTER_CUBIC)    \n",
    "    im = Image.open(image_path).convert(\"RGB\").resize((300,200))\n",
    "    np_img = np.array(im)\n",
    "    return np_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_training_data(data_directory):\n",
    "    i = 0\n",
    "    X = np.ndarray((8677, 200, 300, 3), dtype=np.uint8)\n",
    "    Y = []\n",
    "    \n",
    "    print(\"started to read dataset from {}.\".format(data_directory) )\n",
    "    \n",
    "    for category in return_images_per_category(data_directory):\n",
    "        \n",
    "        if category == 'BACKGROUND_Google':\n",
    "            continue\n",
    "        \n",
    "        print(\"reading class {}\".format(category))\n",
    "        \n",
    "        for image in get_images(category, data_directory):\n",
    "            if not image.endswith('.jpg'):\n",
    "                continue\n",
    "            X[i] = read_image(image)\n",
    "            Y.insert(i,category)\n",
    "            i += 1\n",
    "        print(\"processed {}  of 8678\".format(i+1))\n",
    "    print(\"finished reading dataset.\")\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started to read dataset from data/caltech101.\n",
      "data/caltech101/101_ObjectCategories\n",
      "['gerenuk', 'hawksbill', 'headphone', 'ant', 'butterfly', 'lamp', 'strawberry', 'water_lilly', 'chandelier', 'dragonfly', 'crab', 'pagoda', 'dollar_bill', 'emu', 'inline_skate', 'platypus', 'dalmatian', 'cup', 'airplanes', 'joshua_tree', 'cougar_body', 'grand_piano', 'trilobite', 'brontosaurus', 'wild_cat', 'pigeon', 'dolphin', 'soccer_ball', 'wrench', 'scorpion', 'flamingo_head', 'nautilus', 'accordion', 'cougar_face', 'pyramid', 'camera', 'barrel', 'schooner', 'cellphone', 'panda', 'revolver', 'lobster', 'menorah', 'lotus', 'stapler', 'crocodile', 'chair', 'helicopter', 'minaret', 'starfish', 'ceiling_fan', 'ketch', 'mayfly', 'wheelchair', 'bass', 'yin_yang', 'crocodile_head', 'saxophone', 'beaver', 'mandolin', 'bonsai', 'Leopards', 'car_side', 'ibis', 'electric_guitar', 'kangaroo', 'stegosaurus', 'ferry', 'snoopy', 'umbrella', 'rhino', 'okapi', 'watch', 'brain', 'gramophone', 'scissors', 'rooster', 'cannon', 'binocular', 'anchor', 'octopus', 'buddha', 'laptop', 'windsor_chair', 'hedgehog', 'pizza', 'euphonium', 'stop_sign', 'Motorbikes', 'sea_horse', 'flamingo', 'BACKGROUND_Google', 'ewer', 'garfield', 'crayfish', 'Faces_easy', 'Faces', 'sunflower', 'llama', 'elephant', 'tick', 'metronome']\n",
      "reading class gerenuk\n",
      "processed 35  of 8678\n",
      "reading class hawksbill\n",
      "processed 135  of 8678\n",
      "reading class headphone\n",
      "processed 177  of 8678\n",
      "reading class ant\n",
      "processed 219  of 8678\n",
      "reading class butterfly\n",
      "processed 310  of 8678\n",
      "reading class lamp\n",
      "processed 371  of 8678\n",
      "reading class strawberry\n",
      "processed 406  of 8678\n",
      "reading class water_lilly\n",
      "processed 443  of 8678\n",
      "reading class chandelier\n",
      "processed 550  of 8678\n",
      "reading class dragonfly\n",
      "processed 618  of 8678\n",
      "reading class crab\n",
      "processed 691  of 8678\n",
      "reading class pagoda\n",
      "processed 738  of 8678\n",
      "reading class dollar_bill\n",
      "processed 790  of 8678\n",
      "reading class emu\n",
      "processed 843  of 8678\n",
      "reading class inline_skate\n",
      "processed 874  of 8678\n",
      "reading class platypus\n",
      "processed 908  of 8678\n",
      "reading class dalmatian\n",
      "processed 975  of 8678\n",
      "reading class cup\n",
      "processed 1032  of 8678\n",
      "reading class airplanes\n",
      "processed 1832  of 8678\n",
      "reading class joshua_tree\n",
      "processed 1896  of 8678\n",
      "reading class cougar_body\n",
      "processed 1943  of 8678\n",
      "reading class grand_piano\n",
      "processed 2042  of 8678\n",
      "reading class trilobite\n",
      "processed 2128  of 8678\n",
      "reading class brontosaurus\n",
      "processed 2171  of 8678\n",
      "reading class wild_cat\n",
      "processed 2205  of 8678\n",
      "reading class pigeon\n",
      "processed 2250  of 8678\n",
      "reading class dolphin\n",
      "processed 2315  of 8678\n",
      "reading class soccer_ball\n",
      "processed 2379  of 8678\n",
      "reading class wrench\n",
      "processed 2418  of 8678\n",
      "reading class scorpion\n",
      "processed 2502  of 8678\n",
      "reading class flamingo_head\n",
      "processed 2547  of 8678\n",
      "reading class nautilus\n",
      "processed 2602  of 8678\n",
      "reading class accordion\n",
      "processed 2657  of 8678\n",
      "reading class cougar_face\n",
      "processed 2726  of 8678\n",
      "reading class pyramid\n",
      "processed 2783  of 8678\n",
      "reading class camera\n",
      "processed 2833  of 8678\n",
      "reading class barrel\n",
      "processed 2880  of 8678\n",
      "reading class schooner\n",
      "processed 2943  of 8678\n",
      "reading class cellphone\n",
      "processed 3002  of 8678\n",
      "reading class panda\n",
      "processed 3040  of 8678\n",
      "reading class revolver\n",
      "processed 3122  of 8678\n",
      "reading class lobster\n",
      "processed 3163  of 8678\n",
      "reading class menorah\n",
      "processed 3250  of 8678\n",
      "reading class lotus\n",
      "processed 3316  of 8678\n",
      "reading class stapler\n",
      "processed 3361  of 8678\n",
      "reading class crocodile\n",
      "processed 3411  of 8678\n",
      "reading class chair\n",
      "processed 3473  of 8678\n",
      "reading class helicopter\n",
      "processed 3561  of 8678\n",
      "reading class minaret\n",
      "processed 3637  of 8678\n",
      "reading class starfish\n",
      "processed 3723  of 8678\n",
      "reading class ceiling_fan\n",
      "processed 3770  of 8678\n",
      "reading class ketch\n",
      "processed 3884  of 8678\n",
      "reading class mayfly\n",
      "processed 3924  of 8678\n",
      "reading class wheelchair\n",
      "processed 3983  of 8678\n",
      "reading class bass\n",
      "processed 4037  of 8678\n",
      "reading class yin_yang\n",
      "processed 4097  of 8678\n",
      "reading class crocodile_head\n",
      "processed 4148  of 8678\n",
      "reading class saxophone\n",
      "processed 4188  of 8678\n",
      "reading class beaver\n",
      "processed 4234  of 8678\n",
      "reading class mandolin\n",
      "processed 4277  of 8678\n",
      "reading class bonsai\n",
      "processed 4405  of 8678\n",
      "reading class Leopards\n",
      "processed 4605  of 8678\n",
      "reading class car_side\n",
      "processed 4728  of 8678\n",
      "reading class ibis\n",
      "processed 4808  of 8678\n",
      "reading class electric_guitar\n",
      "processed 4883  of 8678\n",
      "reading class kangaroo\n",
      "processed 4969  of 8678\n",
      "reading class stegosaurus\n",
      "processed 5028  of 8678\n",
      "reading class ferry\n",
      "processed 5095  of 8678\n",
      "reading class snoopy\n",
      "processed 5130  of 8678\n",
      "reading class umbrella\n",
      "processed 5205  of 8678\n",
      "reading class rhino\n",
      "processed 5264  of 8678\n",
      "reading class okapi\n",
      "processed 5303  of 8678\n",
      "reading class watch\n",
      "processed 5542  of 8678\n",
      "reading class brain\n",
      "processed 5640  of 8678\n",
      "reading class gramophone\n",
      "processed 5691  of 8678\n",
      "reading class scissors\n",
      "processed 5730  of 8678\n",
      "reading class rooster\n",
      "processed 5779  of 8678\n",
      "reading class cannon\n",
      "processed 5822  of 8678\n",
      "reading class binocular\n",
      "processed 5855  of 8678\n",
      "reading class anchor\n",
      "processed 5897  of 8678\n",
      "reading class octopus\n",
      "processed 5932  of 8678\n",
      "reading class buddha\n",
      "processed 6017  of 8678\n",
      "reading class laptop\n",
      "processed 6098  of 8678\n",
      "reading class windsor_chair\n",
      "processed 6154  of 8678\n",
      "reading class hedgehog\n",
      "processed 6208  of 8678\n",
      "reading class pizza\n",
      "processed 6261  of 8678\n",
      "reading class euphonium\n",
      "processed 6325  of 8678\n",
      "reading class stop_sign\n",
      "processed 6389  of 8678\n",
      "reading class Motorbikes\n",
      "processed 7187  of 8678\n",
      "reading class sea_horse\n",
      "processed 7244  of 8678\n",
      "reading class flamingo\n",
      "processed 7311  of 8678\n",
      "reading class ewer\n",
      "processed 7396  of 8678\n",
      "reading class garfield\n",
      "processed 7430  of 8678\n",
      "reading class crayfish\n",
      "processed 7500  of 8678\n",
      "reading class Faces_easy\n",
      "processed 7935  of 8678\n",
      "reading class Faces\n",
      "processed 8370  of 8678\n",
      "reading class sunflower\n",
      "processed 8455  of 8678\n",
      "reading class llama\n",
      "processed 8533  of 8678\n",
      "reading class elephant\n",
      "processed 8597  of 8678\n",
      "reading class tick\n",
      "processed 8646  of 8678\n",
      "reading class metronome\n",
      "processed 8678  of 8678\n",
      "finished reading dataset.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Erzeugen der Trainingsdaten\n",
    "#\n",
    "X, Y = create_training_data(localExtractionFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformation der Labels in one-hot encoding\n",
    "#\n",
    "label_encoder = LabelEncoder()\n",
    "Y_integer_encoded = label_encoder.fit_transform(Y)\n",
    "Y_one_hot = to_categorical(Y_integer_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalisieren der Bilddaten\n",
    "#\n",
    "X_normalized = ( X.astype(np.float64) / 255 ) + 0.001\n",
    "del X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split der Daten in Train und Test(validation) Datensätze\n",
    "#\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_normalized, Y_one_hot, test_size=0.25, random_state=42)\n",
    "del X_normalized\n",
    "\n",
    "#\n",
    "# gültige Werte in X_train, X_validation, Y_train, Y_validation, label_encoder, data_directory\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prüfen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Form der Daten\n",
    "#\n",
    "print('Train: X=%s, y=%s' % (X_train.shape, Y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (X_validation.shape, Y_validation.shape))\n",
    "\n",
    "#\n",
    "# Plot von Bildern\n",
    "#\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen eines einfache Modelles\n",
    "#\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(16, (3,3), activation='relu', input_shape=(200,300,3)))\n",
    "model_cnn.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model_cnn.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_cnn.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(101, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compile und Training des Modelles\n",
    "#\n",
    "\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [ModelCheckpoint('model_cnn_weights.h5', monitor='val_acc', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')]\n",
    "\n",
    "model_cnn.fit(X_train, Y_train, batch_size=64, epochs=30, verbose=1, validation_data=(X_validation,Y_validation), callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimiertes Laden der Bilder\n",
    "\n",
    "Die bisherige Ladefunktion hat alle Bilder in den Speicher geladen. Das führt schnell dazu, dass der Hauptspeicher ausgeht. Daher benötigen wir eine Funktion, die Bilder der Reihe nach in den Speicher lädt und für das Training zur Verfügung stellt.\n",
    "\n",
    "Quelle: [https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
